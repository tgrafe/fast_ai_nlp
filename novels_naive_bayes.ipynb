{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.utils.mem import GPUMemTrace #call with mtrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels = pd.read_csv(\"/home/tessa/reading_age/projects/24_novels/chunks/scored.csv\")\n",
    "novels = novels.reset_index()\n",
    "novels = novels[[\"Text\",\"Level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels['Level'] = novels['Level'].apply(lambda x: 'Child' if x!= 'Adult' else 'Adult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels['is_valid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tessa/fast_ai/env/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Level</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREFACE Sir J. M. Barrie's delightful creation...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Then she turned the bedclothes neatly down and...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Darling told him about the weird apparition at...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suddenly the night-lights flickered, waned, an...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No wonder he was crying! But that was not the ...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>George took the fun more soberly, and stuck to...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>Harris said he would introduce us both to the ...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>After which, we managed to get some fitful slu...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>“Yes it’s almost a pity we’ve made up our mind...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>Our fine bronzed countenances and picturesque ...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5276 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Level  is_valid\n",
       "0     PREFACE Sir J. M. Barrie's delightful creation...  Adult      True\n",
       "1     Then she turned the bedclothes neatly down and...  Adult     False\n",
       "2     Darling told him about the weird apparition at...  Adult     False\n",
       "3     Suddenly the night-lights flickered, waned, an...  Adult     False\n",
       "4     No wonder he was crying! But that was not the ...  Adult     False\n",
       "...                                                 ...    ...       ...\n",
       "5271  George took the fun more soberly, and stuck to...  Adult     False\n",
       "5272  Harris said he would introduce us both to the ...  Adult     False\n",
       "5273  After which, we managed to get some fitful slu...  Adult     False\n",
       "5274  “Yes it’s almost a pity we’ve made up our mind...  Adult     False\n",
       "5275  Our fine bronzed countenances and picturesque ...  Adult      True\n",
       "\n",
       "[5276 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novels['is_valid'][::5] = True\n",
    "novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create labelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "novel_lablist = (TextList.from_df(novels,cols = 'Text')).split_from_df(col = 'is_valid').label_from_df(cols='Level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_term_matrix(text_list, n_terms):\n",
    "    \n",
    "    # inputs:\n",
    "    #    text_list, a TextList object\n",
    "    #    n_terms, the number of tokens in our IMDb vocabulary\n",
    "    \n",
    "    # output: \n",
    "    #    the CSR format sparse representation of the document-term matrix in the form of a\n",
    "    #    scipy.sparse.csr.csr_matrix object\n",
    "\n",
    "    \n",
    "    # initialize arrays\n",
    "    values = []\n",
    "    column_indices = []\n",
    "    row_pointer = []\n",
    "    row_pointer.append(0)\n",
    "\n",
    "    # from the TextList object\n",
    "    for _, doc in enumerate(text_list):\n",
    "        feature_counter = Counter(doc.data)\n",
    "        column_indices.extend(feature_counter.keys())\n",
    "        values.extend(feature_counter.values())\n",
    "        # Tack on N (number of nonzero elements in the matrix) to the end of the row_pointer array\n",
    "        row_pointer.append(len(values))\n",
    "        \n",
    "    return scipy.sparse.csr_matrix((values, column_indices, row_pointer),\n",
    "                                   shape=(len(row_pointer) - 1, n_terms),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 96 ms, total: 1.65 s\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_doc_term = get_doc_term_matrix(novel_lablist.train.x, len(novel_lablist.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4220, 19744)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 19744)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_doc_term = get_doc_term_matrix(novel_lablist.valid.x, len(novel_lablist.vocab.itos))\n",
    "valid_doc_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adult': 0, 'Child': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_lablist.classes\n",
    "novel_lablist.train.y.c2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adult'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_lablist.train.y.classes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the class priors for adult & child\n",
    "child_prior = novel_lablist.train.y.items.mean()\n",
    "adult_prior = 1 - child_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.log(adult_prior/child_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9444389791664403"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2,    3, ..., 4216, 4217, 4218, 4219])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_rows = np.squeeze(np.argwhere(novel_lablist.y.items == novel_lablist.train.y.c2i['Adult']))\n",
    "adult_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[30913,     0,  4009,     0, ...,     3,     0,     0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_count = train_doc_term[adult_rows].sum(axis = 0)\n",
    "adult_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.605778e-02, 5.194338e-07, 2.082930e-03, 5.194338e-07, ..., 2.077735e-06, 5.194338e-07, 5.194338e-07,\n",
       "         5.194338e-07]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_liklihood = (adult_count + 1)/(adult_count.sum() + 1)\n",
    "adult_liklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_rows = np.squeeze(np.argwhere(novel_lablist.y.items == novel_lablist.train.y.c2i['Child']))\n",
    "len(child_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_count = train_doc_term[child_rows].sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19744)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.536428e-03, 8.932719e-06, 1.893736e-03, 8.932719e-06, ..., 8.932719e-06, 8.932719e-06, 8.932719e-06,\n",
       "         8.932719e-06]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_liklihood = (child_count + 1)/(child_count.sum() + 1)\n",
    "child_liklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[10, 11,  5, 71,  9]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argpartition(child_liklihood, -5, axis = 1)[0,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2.346733, -2.844737,  0.095224, -2.844737, ..., -1.458442, -2.844737, -2.844737, -2.844737]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_ratio = np.log(adult_liklihood/child_liklihood)\n",
    "log_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([109, 106,  94,  65,  78,  51,  39,  41,  40,  36])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(np.argpartition(log_ratio,-10)[0,-10:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[']',\n",
       " '[',\n",
       " 'cosette',\n",
       " 'bloom',\n",
       " 'valjean',\n",
       " 'mrs.',\n",
       " '(',\n",
       " 'marius',\n",
       " 'jean',\n",
       " ')',\n",
       " 'mr.',\n",
       " '“',\n",
       " '‘',\n",
       " '”',\n",
       " '’s',\n",
       " 'upon',\n",
       " 'n’t',\n",
       " '–',\n",
       " '—',\n",
       " '’']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest args - should be most adulty\n",
    "[novel_lablist.vocab.itos[i] for i in np.asarray((np.argpartition(log_ratio,-20)[0,-20:]))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neverland',\n",
       " 'http',\n",
       " 'onto',\n",
       " 'silliness',\n",
       " 'classroom',\n",
       " 'english-e-books.net',\n",
       " 'vampires',\n",
       " 'unwise',\n",
       " 'hypnotize',\n",
       " 'okay',\n",
       " '\\t',\n",
       " 'lawrence',\n",
       " 'anymore',\n",
       " 'rented',\n",
       " 'greetings',\n",
       " 'nanny',\n",
       " 'kilometres',\n",
       " \"'\",\n",
       " 'cabdriver',\n",
       " 'hythe']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smallest args should be most childy\n",
    "[novel_lablist.vocab.itos[i] for i in np.asarray((np.argpartition(log_ratio,20)[0,:20]))[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398104265402843"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FULL\n",
    "# greater than 0 is adult\n",
    "train_prec = (np.squeeze(np.asarray((train_doc_term @ log_ratio.T + bias)>0)) == (novel_lablist.train.y.items == 0)).mean()\n",
    "train_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9365530303030303"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_prec = (np.squeeze(np.asarray((valid_doc_term @ log_ratio.T + bias)>0)) == (novel_lablist.valid.y.items == 0)).mean()\n",
    "valid_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248815165876777"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BINARIZED\n",
    "train_prec = (np.squeeze(np.asarray((train_doc_term.sign() @ log_ratio.T + bias)>0)) == (novel_lablist.train.y.items == 0)).mean()\n",
    "train_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9204545454545454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_prec = (np.squeeze(np.asarray((valid_doc_term.sign() @ log_ratio.T + bias)>0)) == (novel_lablist.valid.y.items == 0)).mean()\n",
    "valid_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is 0.9962121212121212 using the full doc-term matrix\n"
     ]
    }
   ],
   "source": [
    "# FULL\n",
    "m = LogisticRegression(C=0.1, dual=False,solver = 'liblinear')\n",
    "# 'liblinear' and 'newton-cg' solvers both get 0.88328 accuracy\n",
    "# 'sag', 'saga', and 'lbfgs' don't converge\n",
    "m.fit(train_doc_term, novel_lablist.train.y.items.astype(int))\n",
    "preds = m.predict(valid_doc_term)\n",
    "valid_accuracy = (preds==novel_lablist.valid.y.items).mean()\n",
    "print(f'Validation accuracy is {valid_accuracy} using the full doc-term matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is 0.9971590909090909 using the binarized doc-term matrix\n"
     ]
    }
   ],
   "source": [
    "# BINARIZED\n",
    "m = LogisticRegression(C=0.1, dual=False,solver = 'liblinear')\n",
    "m.fit(train_doc_term.sign(), novel_lablist.train.y.items.astype(int))\n",
    "preds = m.predict(valid_doc_term.sign())\n",
    "valid_accuracy = (preds==novel_lablist.valid.y.items).mean()\n",
    "print(f'Validation accuracy is {valid_accuracy} using the binarized doc-term matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(ngram_range=(1,3), preprocessor=noop, tokenizer=noop, max_features=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = novel_lablist.train.x\n",
    "train_words = [[novel_lablist.vocab.itos[o] for o in doc.data] for doc in novel_lablist.train.x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 4.59 s, total: 17.9 s\n",
      "Wall time: 18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4220x400000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3362605 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_ngram_doc_matrix_veczr = veczr.fit_transform(train_words)\n",
    "train_ngram_doc_matrix_veczr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_docs = novel_lablist.valid.x\n",
    "valid_words = [[novel_lablist.vocab.itos[o] for o in doc.data] for doc in novel_lablist.valid.x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 s, sys: 140 ms, total: 3.48 s\n",
      "Wall time: 3.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1056x400000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1016571 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "valid_ngram_doc_matrix_veczr = veczr.fit_transform(valid_words)\n",
    "valid_ngram_doc_matrix_veczr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = veczr.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  = 0.9081439393939394 for Logistic Regression, with full trigram counts from `CountVectorizer`\n"
     ]
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=False, solver = 'liblinear')\n",
    "m.fit(train_ngram_doc_matrix_veczr, novel_lablist.y.items);\n",
    "\n",
    "preds = m.predict(valid_ngram_doc_matrix_veczr)\n",
    "accuracy =(preds==novel_lablist.valid.y.items).mean()\n",
    "print(f'Accuracy  = {accuracy} for Logistic Regression, with full trigram counts from `CountVectorizer`' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9583333333333334 for Logistic Regression, with binarized trigram counts from `CountVectorizer`\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "m = LogisticRegression(C=0.1, dual=False, solver = 'liblinear')\n",
    "m.fit(train_ngram_doc_matrix_veczr.sign(), novel_lablist.y.items);\n",
    "\n",
    "# get predictions\n",
    "preds = m.predict(valid_ngram_doc_matrix_veczr.sign())\n",
    "valid_labels = [label == novel_lablist.valid.y.c2i['Child'] for label in novel_lablist.valid.y.items]\n",
    "\n",
    "# check accuracy\n",
    "accuracy = (preds==valid_labels).mean()\n",
    "print(f'Accuracy = {accuracy} for Logistic Regression, with binarized trigram counts from `CountVectorizer`' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adult': 0, 'Child': 1}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_lablist.valid.y.c2i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bias_and_log_ratio(y_items, train_doc_term):\n",
    "    # bias\n",
    "    c1_prior = y_items.mean()\n",
    "    bias = np.log(c1_prior/(1- c1_prior))\n",
    "    \n",
    "    # log ratio\n",
    "    c1_rows = np.squeeze(np.argwhere(y_items == 1))\n",
    "    c1_count = train_doc_term[c1_rows].sum(axis = 0)\n",
    "    c1_liklihood = (c1_count + 1)/(c1_count.sum() + 1)\n",
    "    \n",
    "    c0_rows = np.squeeze(np.argwhere(y_items == 0))\n",
    "    c0_count = train_doc_term[c0_rows].sum(axis = 0)\n",
    "    c0_liklihood = (c0_count + 1)/(c0_count.sum() + 1)\n",
    "    \n",
    "    log_ratio = np.log(c1_liklihood/c0_liklihood)\n",
    "    \n",
    "    return bias, log_ratio\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Count_style</th>\n",
       "      <th>Term_doc</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>full</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.050189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>binary</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.050189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>binary</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.123223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>full</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.599052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>full</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.908144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>binary</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.920455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>binary</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.924882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>full</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.936553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>full</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.939810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>binary</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>full</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.996212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>binary</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.997159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Count_style                  Term_doc   Data_type  \\\n",
       "7                 Bayes        full  count_vectorizer_trigram  Validation   \n",
       "10                Bayes      binary  count_vectorizer_trigram  Validation   \n",
       "9                 Bayes      binary  count_vectorizer_trigram    Training   \n",
       "6                 Bayes        full  count_vectorizer_trigram    Training   \n",
       "8   Logistic regression        full  count_vectorizer_trigram  Validation   \n",
       "4                 Bayes      binary           classic_unigram  Validation   \n",
       "3                 Bayes      binary           classic_unigram    Training   \n",
       "1                 Bayes        full           classic_unigram  Validation   \n",
       "0                 Bayes        full           classic_unigram    Training   \n",
       "11  Logistic regression      binary  count_vectorizer_trigram  Validation   \n",
       "2   Logistic regression        full           classic_unigram  Validation   \n",
       "5   Logistic regression      binary           classic_unigram  Validation   \n",
       "\n",
       "      Result  \n",
       "7   0.050189  \n",
       "10  0.050189  \n",
       "9   0.123223  \n",
       "6   0.599052  \n",
       "8   0.908144  \n",
       "4   0.920455  \n",
       "3   0.924882  \n",
       "1   0.936553  \n",
       "0   0.939810  \n",
       "11  0.958333  \n",
       "2   0.996212  \n",
       "5   0.997159  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify(label_list):\n",
    "    term_docs = []\n",
    "    \n",
    "    # CREATE TERM DOCS\n",
    "    # class unigram\n",
    "    train_doc_term = get_doc_term_matrix(label_list.train.x, len(label_list.vocab.itos))\n",
    "    valid_doc_term = get_doc_term_matrix(label_list.valid.x, len(label_list.vocab.itos))\n",
    "    term_docs.append(('classic_unigram',train_doc_term, valid_doc_term))\n",
    "    \n",
    "    # count vectorizer trigram\n",
    "    veczr = CountVectorizer(ngram_range=(1,3), preprocessor=noop, tokenizer=noop, max_features=400000)\n",
    "    train_words = [[label_list.vocab.itos[o] for o in doc.data] for doc in label_list.train.x]\n",
    "    train_ngram_doc_matrix_veczr = veczr.fit_transform(train_words)\n",
    "    \n",
    "    valid_words = [[label_list.vocab.itos[o] for o in doc.data] for doc in label_list.valid.x]\n",
    "    valid_ngram_doc_matrix_veczr = veczr.fit_transform(valid_words)\n",
    "    term_docs.append(('count_vectorizer_trigram', train_ngram_doc_matrix_veczr, valid_ngram_doc_matrix_veczr))\n",
    "\n",
    "    \n",
    "    df_list = []\n",
    "    # RUN MODELS\n",
    "    for term_doc_name, train_doc_term, valid_doc_term in term_docs:\n",
    "        bias, log_ratio = get_bias_and_log_ratio(label_list.train.y.items, train_doc_term)\n",
    "       \n",
    "        m = LogisticRegression(C=0.1, dual=False,solver = 'liblinear')\n",
    "        \n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                count_style = 'full'\n",
    "            else:\n",
    "                count_style = 'binary'\n",
    "                train_doc_term = train_doc_term.sign()\n",
    "                valid_doc_term = valid_doc_term.sign()\n",
    "\n",
    "            train_prec = (np.squeeze(np.asarray((train_doc_term @ log_ratio.T + bias)>0)) == label_list.train.y.items).mean()\n",
    "            valid_prec = (np.squeeze(np.asarray((valid_doc_term @ log_ratio.T + bias)>0)) == label_list.valid.y.items).mean()\n",
    "            df_list.append({'Model':'Bayes', 'Count_style':count_style, 'Term_doc':term_doc_name, 'Data_type':'Training','Result':train_prec})\n",
    "            df_list.append({'Model':'Bayes', 'Count_style':count_style, 'Term_doc':term_doc_name, 'Data_type':'Validation','Result':valid_prec})\n",
    "\n",
    "\n",
    "            m.fit(train_doc_term, label_list.train.y.items.astype(int))\n",
    "            preds = m.predict(valid_doc_term)\n",
    "            valid_accuracy = (preds==label_list.valid.y.items).mean()\n",
    "            df_list.append({'Model':'Logistic regression', 'Count_style':count_style, 'Term_doc':term_doc_name, 'Data_type':'Validation','Result':valid_accuracy})\n",
    "\n",
    "    results = pd.DataFrame(df_list)\n",
    "    results = results.sort_values('Result')\n",
    "        \n",
    "    return results\n",
    "    \n",
    "\n",
    "classify(novel_lablist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tessa/fast_ai/env/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_novs = pd.read_csv(\"/home/tessa/reading_age/projects/24_novels/chunks/scored.csv\")\n",
    "df_novs = df_novs.reset_index()[[\"Name\",\"Text\"]]\n",
    "df_novs[\"Label\"] = df_novs[\"Name\"].apply(lambda x: 'Les_Mis' if x == 'Les_Miserables' else 'Not_les_mis')\n",
    "df_novs['is_valid'] = False\n",
    "df_novs['is_valid'][::5] = True\n",
    "lesmis_lablist = (TextList.from_df(df_novs,cols = 'Text')).split_from_df(col = 'is_valid').label_from_df(cols='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Count_style</th>\n",
       "      <th>Term_doc</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>full</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.294508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>binary</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.294508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>full</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.614583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>binary</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.679924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>full</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.988636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>full</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.993128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>binary</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.995265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>binary</td>\n",
       "      <td>count_vectorizer_trigram</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.995498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>full</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.996212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>binary</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.996212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>full</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.996682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>binary</td>\n",
       "      <td>classic_unigram</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.997867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Count_style                  Term_doc   Data_type  \\\n",
       "7                 Bayes        full  count_vectorizer_trigram  Validation   \n",
       "10                Bayes      binary  count_vectorizer_trigram  Validation   \n",
       "8   Logistic regression        full  count_vectorizer_trigram  Validation   \n",
       "11  Logistic regression      binary  count_vectorizer_trigram  Validation   \n",
       "1                 Bayes        full           classic_unigram  Validation   \n",
       "6                 Bayes        full  count_vectorizer_trigram    Training   \n",
       "4                 Bayes      binary           classic_unigram  Validation   \n",
       "9                 Bayes      binary  count_vectorizer_trigram    Training   \n",
       "2   Logistic regression        full           classic_unigram  Validation   \n",
       "5   Logistic regression      binary           classic_unigram  Validation   \n",
       "0                 Bayes        full           classic_unigram    Training   \n",
       "3                 Bayes      binary           classic_unigram    Training   \n",
       "\n",
       "      Result  \n",
       "7   0.294508  \n",
       "10  0.294508  \n",
       "8   0.614583  \n",
       "11  0.679924  \n",
       "1   0.988636  \n",
       "6   0.993128  \n",
       "4   0.995265  \n",
       "9   0.995498  \n",
       "2   0.996212  \n",
       "5   0.996212  \n",
       "0   0.996682  \n",
       "3   0.997867  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# well seems to be pretty good at identifying les mis!\n",
    "classify(lesmis_lablist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
